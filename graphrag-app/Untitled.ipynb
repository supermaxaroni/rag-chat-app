{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "766d00b9-3108-48d7-bcf4-e7d81e66e352",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (3829690924.py, line 37)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn qa\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "@st.cache_resource\n",
    "def setup_qa_chain():\n",
    "    # Load and embed documents\n",
    "    from langchain.document_loaders import TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "def load_utf8_safe(path):\n",
    "    try:\n",
    "        return TextLoader(path, encoding=\"utf-8\").load()\n",
    "    except UnicodeDecodeError:\n",
    "        return TextLoader(path, encoding=\"cp1252\").load()  # Windows fallback\n",
    "\n",
    "docs = []\n",
    "for filepath in Path(\"documents\").rglob(\"*.txt\"):\n",
    "    docs.extend(load_utf8_safe(str(filepath)))\n",
    "\n",
    "    docs = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectordb = FAISS.from_documents(chunks, embedding)\n",
    "\n",
    "    llm = Ollama(model=\"llama3\")\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever())\n",
    "    return qa\n",
    "\n",
    "st.set_page_config(page_title=\"Local RAG Chat\", page_icon=\"ðŸ’¬\")\n",
    "st.title(\"ðŸ§  RAG Chat with LLaMA 3\")\n",
    "\n",
    "qa = setup_qa_chain()\n",
    "\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "\n",
    "user_input = st.chat_input(\"Ask something about your documents...\")\n",
    "\n",
    "if user_input:\n",
    "    with st.spinner(\"Thinking...\"):\n",
    "        result = qa.invoke(user_input)\n",
    "\n",
    "    st.session_state.chat_history.append((\"user\", user_input))\n",
    "    st.session_state.chat_history.append((\"bot\", result[\"result\"]))\n",
    "\n",
    "# Display chat history\n",
    "for role, text in st.session_state.chat_history:\n",
    "    if role == \"user\":\n",
    "        st.chat_message(\"user\").markdown(text)\n",
    "    else:\n",
    "        st.chat_message(\"assistant\").markdown(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5509367d-afa4-46d3-9168-5a204ccf15da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfairbourne\\AppData\\Local\\Temp\\ipykernel_23312\\1408457153.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive - Arch Capital Group\\Documents\\Innovation Lab mfairbourne\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:84\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m splitter = RecursiveCharacterTextSplitter(chunk_size=\u001b[32m500\u001b[39m, chunk_overlap=\u001b[32m50\u001b[39m)\n\u001b[32m      2\u001b[39m chunks = splitter.split_documents(docs)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m embedding = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m vectordb = FAISS.from_documents(chunks, embedding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive - Arch Capital Group\\Documents\\Innovation Lab mfairbourne\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:222\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    221\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive - Arch Capital Group\\Documents\\Innovation Lab mfairbourne\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:87\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.client = sentence_transformers.SentenceTransformer(\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_name, cache_folder=\u001b[38;5;28mself\u001b[39m.cache_folder, **\u001b[38;5;28mself\u001b[39m.model_kwargs\n\u001b[32m     94\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectordb = FAISS.from_documents(chunks, embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb247f19-eb9a-46b0-aed7-33562237dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\")\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba63d7b-162e-4efc-866e-4babce0344a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is this document about?\"\n",
    "response = qa.invoke(question)\n",
    "print(response[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892023a3-c61a-4a54-a990-bdab6fa39544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "while True:\n",
    "    q = input(\"\\nAsk a question (or 'exit'): \")\n",
    "    if q.lower() == \"exit\":\n",
    "        break\n",
    "    a = qa.invoke(q)[\"result\"]\n",
    "    display(Markdown(f\"**Answer:** {a}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322cfd3-b81f-4709-814e-6f6b7640a818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
